2024-06-01 14:42:27,785 - INFO - Log directory: ./libcity/log
2024-06-01 14:42:27,786 - INFO - Begin pipeline, task=traffic_state_pred, model_name=GEML, dataset_name=NYCTAXI_OD, exp_id=67792
2024-06-01 14:42:27,786 - INFO - {'task': 'traffic_state_pred', 'model': 'GEML', 'dataset': 'NYCTAXI_OD', 'saved_model': True, 'train': True, 'seed': 0, 'gpu_id': 1, 'train_rate': 0.8, 'eval_rate': 0.1, 'max_epoch': 100, 'dataset_class': 'TrafficStateOdDataset', 'executor': 'GEMLExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 128, 'p_interval': 1, 'loss_p0': 0.5, 'loss_p1': 0.25, 'loss_p2': 0.25, 'scaler': 'minmax01', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'use_row_column': True, 'learner': 'adam', 'learning_rate': 0.001, 'weight_decay': 1e-06, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_decay': False, 'clip_grad_norm': False, 'use_early_stop': True, 'patience': 50, 'batch_size': 64, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'input_window': 8, 'output_window': 1, 'gpu': True, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'max_grad_norm': 1.0, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {}}, 'od': {'including_types': ['state'], 'state': {'origin_id': 'geo_id', 'destination_id': 'geo_id', 'flow': 'num'}}, 'data_col': ['flow'], 'data_files': ['NYCTAXI202310-202403'], 'geo_file': 'NYCTAXI202310-202403', 'rel_file': 'NYCTAXI202310-202403', 'output_dim': 1, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'time_intervals': 3600, 'device': device(type='cuda', index=1), 'exp_id': 67792}
2024-06-01 14:42:27,816 - INFO - Loaded file NYCTAXI202310-202403.geo, num_nodes=263
2024-06-01 14:42:27,851 - INFO - set_weight_link_or_dist: dist
2024-06-01 14:42:27,851 - INFO - init_weight_inf_or_zero: inf
2024-06-01 14:42:27,976 - INFO - Loaded file NYCTAXI202310-202403.rel, shape=(263, 263)
2024-06-01 14:42:27,976 - INFO - Start Calculate the weight by Gauss kernel!
2024-06-01 14:42:27,999 - INFO - set_weight_link_or_dist: dist
2024-06-01 14:42:27,999 - INFO - init_weight_inf_or_zero: inf
2024-06-01 14:42:28,123 - INFO - Loaded file NYCTAXI202310-202403.rel, shape=(263, 263)
2024-06-01 14:42:28,123 - INFO - Start Calculate the weight by Gauss kernel!
2024-06-01 14:42:28,124 - INFO - Loading ./libcity/cache/dataset_cache/od_based_NYCTAXI_OD_8_1_0.8_0.1_minmax01_64_False_True_False_True.npz
2024-06-01 14:43:11,978 - INFO - train	x: (3506, 8, 263, 263, 1), y: (3506, 1, 263, 263, 1)
2024-06-01 14:43:11,979 - INFO - eval	x: (439, 8, 263, 263, 1), y: (439, 1, 263, 263, 1)
2024-06-01 14:43:11,979 - INFO - test	x: (438, 8, 263, 263, 1), y: (438, 1, 263, 263, 1)
2024-06-01 14:43:14,917 - INFO - MinMax01Scaler max: 103.0, min: 0.0
2024-06-01 14:43:14,917 - INFO - NoneScaler
2024-06-01 14:43:42,293 - INFO - GEML(
  (GCN_ge): GCN(
    (gcn): ModuleList(
      (0-1): 2 x GraphConvolution(
        (activation): ReLU()
      )
    )
  )
  (GCN_se): GCN(
    (gcn): ModuleList(
      (0-1): 2 x GraphConvolution(
        (activation): ReLU()
      )
    )
  )
  (LSTM): SLSTM(
    (f_gate): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): Softmax(dim=1)
    )
    (i_gate): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): Softmax(dim=1)
    )
    (o_gate): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): Softmax(dim=1)
    )
    (g_gate): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): Tanh()
    )
    (tanh): Tanh()
  )
  (mutiLearning): MutiLearning()
)
2024-06-01 14:43:42,293 - INFO - GCN_ge.gcn.0.weight	torch.Size([263, 128])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - GCN_ge.gcn.1.weight	torch.Size([128, 128])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - GCN_se.gcn.0.weight	torch.Size([263, 128])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - GCN_se.gcn.1.weight	torch.Size([128, 128])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - LSTM.f_gate.0.weight	torch.Size([256, 512])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - LSTM.f_gate.0.bias	torch.Size([256])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - LSTM.i_gate.0.weight	torch.Size([256, 512])	cuda:1	True
2024-06-01 14:43:42,293 - INFO - LSTM.i_gate.0.bias	torch.Size([256])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - LSTM.o_gate.0.weight	torch.Size([256, 512])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - LSTM.o_gate.0.bias	torch.Size([256])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - LSTM.g_gate.0.weight	torch.Size([256, 512])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - LSTM.g_gate.0.bias	torch.Size([256])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - mutiLearning.transition	torch.Size([256, 256])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - mutiLearning.project_in	torch.Size([256, 1])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - mutiLearning.project_out	torch.Size([256, 1])	cuda:1	True
2024-06-01 14:43:42,294 - INFO - Total parameter numbers: 691456
2024-06-01 14:43:42,294 - INFO - You select `adam` optimizer.
2024-06-01 14:43:42,294 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-06-01 14:43:42,294 - INFO - Start training ...
2024-06-01 14:43:42,294 - INFO - num_batches:55
2024-06-01 14:46:52,014 - INFO - epoch complete!
2024-06-01 14:46:52,014 - INFO - evaluating now!
2024-06-01 14:47:13,590 - INFO - Epoch [0/100] train_loss: 632.9785, val_loss: 748.9063, lr: 0.001000, 211.30s
2024-06-01 14:47:13,603 - INFO - Saved model at 0
2024-06-01 14:47:13,603 - INFO - Val loss decrease from inf to 748.9063, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch0.tar
2024-06-01 14:50:13,235 - INFO - epoch complete!
2024-06-01 14:50:13,235 - INFO - evaluating now!
2024-06-01 14:50:34,691 - INFO - Epoch [1/100] train_loss: 633.0183, val_loss: 748.9675, lr: 0.001000, 201.09s
2024-06-01 14:53:34,178 - INFO - epoch complete!
2024-06-01 14:53:34,179 - INFO - evaluating now!
2024-06-01 14:53:56,233 - INFO - Epoch [2/100] train_loss: 632.9761, val_loss: 748.9680, lr: 0.001000, 201.54s
2024-06-01 15:06:33,133 - INFO - epoch complete!
2024-06-01 15:06:33,134 - INFO - evaluating now!
2024-06-01 15:08:13,886 - INFO - Epoch [3/100] train_loss: 632.9775, val_loss: 748.9719, lr: 0.001000, 857.65s
2024-06-01 15:22:09,856 - INFO - epoch complete!
2024-06-01 15:22:09,857 - INFO - evaluating now!
2024-06-01 15:23:50,771 - INFO - Epoch [4/100] train_loss: 632.9784, val_loss: 748.9673, lr: 0.001000, 936.88s
2024-06-01 15:37:41,490 - INFO - epoch complete!
2024-06-01 15:37:41,491 - INFO - evaluating now!
2024-06-01 15:39:22,400 - INFO - Epoch [5/100] train_loss: 632.9777, val_loss: 748.9698, lr: 0.001000, 931.63s
2024-06-01 15:53:20,375 - INFO - epoch complete!
2024-06-01 15:53:20,376 - INFO - evaluating now!
2024-06-01 15:54:58,498 - INFO - Epoch [6/100] train_loss: 632.9349, val_loss: 745.6796, lr: 0.001000, 936.10s
2024-06-01 15:54:58,513 - INFO - Saved model at 6
2024-06-01 15:54:58,513 - INFO - Val loss decrease from 748.9063 to 745.6796, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch6.tar
2024-06-01 16:08:52,153 - INFO - epoch complete!
2024-06-01 16:08:52,153 - INFO - evaluating now!
2024-06-01 16:10:31,061 - INFO - Epoch [7/100] train_loss: 412.5047, val_loss: 360.2553, lr: 0.001000, 932.55s
2024-06-01 16:10:31,076 - INFO - Saved model at 7
2024-06-01 16:10:31,076 - INFO - Val loss decrease from 745.6796 to 360.2553, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch7.tar
2024-06-01 16:24:23,716 - INFO - epoch complete!
2024-06-01 16:24:23,717 - INFO - evaluating now!
2024-06-01 16:26:03,600 - INFO - Epoch [8/100] train_loss: 289.5068, val_loss: 331.2124, lr: 0.001000, 932.52s
2024-06-01 16:26:03,614 - INFO - Saved model at 8
2024-06-01 16:26:03,614 - INFO - Val loss decrease from 360.2553 to 331.2124, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch8.tar
2024-06-01 16:39:57,662 - INFO - epoch complete!
2024-06-01 16:39:57,663 - INFO - evaluating now!
2024-06-01 16:41:38,547 - INFO - Epoch [9/100] train_loss: 274.0699, val_loss: 353.9641, lr: 0.001000, 934.93s
2024-06-01 16:55:30,032 - INFO - epoch complete!
2024-06-01 16:55:30,032 - INFO - evaluating now!
2024-06-01 16:57:10,971 - INFO - Epoch [10/100] train_loss: 263.8212, val_loss: 310.8923, lr: 0.001000, 932.42s
2024-06-01 16:57:10,986 - INFO - Saved model at 10
2024-06-01 16:57:10,986 - INFO - Val loss decrease from 331.2124 to 310.8923, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch10.tar
2024-06-01 17:11:05,049 - INFO - epoch complete!
2024-06-01 17:11:05,049 - INFO - evaluating now!
2024-06-01 17:12:46,376 - INFO - Epoch [11/100] train_loss: 251.9697, val_loss: 307.6070, lr: 0.001000, 935.39s
2024-06-01 17:12:46,391 - INFO - Saved model at 11
2024-06-01 17:12:46,391 - INFO - Val loss decrease from 310.8923 to 307.6070, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch11.tar
2024-06-01 17:26:40,566 - INFO - epoch complete!
2024-06-01 17:26:40,566 - INFO - evaluating now!
2024-06-01 17:28:20,786 - INFO - Epoch [12/100] train_loss: 245.2027, val_loss: 290.7211, lr: 0.001000, 934.39s
2024-06-01 17:28:20,800 - INFO - Saved model at 12
2024-06-01 17:28:20,800 - INFO - Val loss decrease from 307.6070 to 290.7211, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch12.tar
2024-06-01 17:42:15,472 - INFO - epoch complete!
2024-06-01 17:42:15,473 - INFO - evaluating now!
2024-06-01 17:43:55,941 - INFO - Epoch [13/100] train_loss: 238.9821, val_loss: 277.6311, lr: 0.001000, 935.14s
2024-06-01 17:43:55,956 - INFO - Saved model at 13
2024-06-01 17:43:55,956 - INFO - Val loss decrease from 290.7211 to 277.6311, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch13.tar
2024-06-01 17:57:47,622 - INFO - epoch complete!
2024-06-01 17:57:47,623 - INFO - evaluating now!
2024-06-01 17:59:28,797 - INFO - Epoch [14/100] train_loss: 233.3686, val_loss: 277.3994, lr: 0.001000, 932.84s
2024-06-01 17:59:28,812 - INFO - Saved model at 14
2024-06-01 17:59:28,812 - INFO - Val loss decrease from 277.6311 to 277.3994, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch14.tar
2024-06-01 18:13:25,272 - INFO - epoch complete!
2024-06-01 18:13:25,272 - INFO - evaluating now!
2024-06-01 18:15:04,114 - INFO - Epoch [15/100] train_loss: 228.5335, val_loss: 301.7711, lr: 0.001000, 935.30s
2024-06-01 18:28:58,748 - INFO - epoch complete!
2024-06-01 18:28:58,748 - INFO - evaluating now!
2024-06-01 18:30:39,207 - INFO - Epoch [16/100] train_loss: 226.9675, val_loss: 264.2390, lr: 0.001000, 935.09s
2024-06-01 18:30:39,221 - INFO - Saved model at 16
2024-06-01 18:30:39,221 - INFO - Val loss decrease from 277.3994 to 264.2390, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch16.tar
2024-06-01 18:44:30,490 - INFO - epoch complete!
2024-06-01 18:44:30,491 - INFO - evaluating now!
2024-06-01 18:46:11,012 - INFO - Epoch [17/100] train_loss: 221.5911, val_loss: 277.1743, lr: 0.001000, 931.79s
2024-06-01 19:00:05,157 - INFO - epoch complete!
2024-06-01 19:00:05,157 - INFO - evaluating now!
2024-06-01 19:01:45,702 - INFO - Epoch [18/100] train_loss: 219.4284, val_loss: 282.4759, lr: 0.001000, 934.69s
2024-06-01 19:15:38,572 - INFO - epoch complete!
2024-06-01 19:15:38,573 - INFO - evaluating now!
2024-06-01 19:17:19,993 - INFO - Epoch [19/100] train_loss: 216.9061, val_loss: 269.2173, lr: 0.001000, 934.29s
2024-06-01 19:31:14,376 - INFO - epoch complete!
2024-06-01 19:31:14,376 - INFO - evaluating now!
2024-06-01 19:32:55,431 - INFO - Epoch [20/100] train_loss: 214.1691, val_loss: 276.8082, lr: 0.001000, 935.44s
2024-06-01 19:46:48,998 - INFO - epoch complete!
2024-06-01 19:46:48,999 - INFO - evaluating now!
2024-06-01 19:48:30,230 - INFO - Epoch [21/100] train_loss: 213.6223, val_loss: 267.7788, lr: 0.001000, 934.80s
2024-06-01 20:02:26,449 - INFO - epoch complete!
2024-06-01 20:02:26,450 - INFO - evaluating now!
2024-06-01 20:04:06,210 - INFO - Epoch [22/100] train_loss: 212.6295, val_loss: 271.6561, lr: 0.001000, 935.98s
2024-06-01 20:18:00,436 - INFO - epoch complete!
2024-06-01 20:18:00,436 - INFO - evaluating now!
2024-06-01 20:19:41,917 - INFO - Epoch [23/100] train_loss: 211.5323, val_loss: 265.9763, lr: 0.001000, 935.71s
2024-06-01 20:33:36,223 - INFO - epoch complete!
2024-06-01 20:33:36,223 - INFO - evaluating now!
2024-06-01 20:35:16,934 - INFO - Epoch [24/100] train_loss: 210.0736, val_loss: 264.4214, lr: 0.001000, 935.02s
2024-06-01 20:49:06,874 - INFO - epoch complete!
2024-06-01 20:49:06,898 - INFO - evaluating now!
2024-06-01 20:50:47,237 - INFO - Epoch [25/100] train_loss: 212.9590, val_loss: 257.6097, lr: 0.001000, 930.30s
2024-06-01 20:50:47,252 - INFO - Saved model at 25
2024-06-01 20:50:47,252 - INFO - Val loss decrease from 264.2390 to 257.6097, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch25.tar
2024-06-01 21:04:37,744 - INFO - epoch complete!
2024-06-01 21:04:37,744 - INFO - evaluating now!
2024-06-01 21:06:18,688 - INFO - Epoch [26/100] train_loss: 211.2042, val_loss: 283.6251, lr: 0.001000, 931.44s
2024-06-01 21:20:10,524 - INFO - epoch complete!
2024-06-01 21:20:10,524 - INFO - evaluating now!
2024-06-01 21:21:51,000 - INFO - Epoch [27/100] train_loss: 209.5708, val_loss: 263.9533, lr: 0.001000, 932.31s
2024-06-01 21:35:42,613 - INFO - epoch complete!
2024-06-01 21:35:42,614 - INFO - evaluating now!
2024-06-01 21:37:23,565 - INFO - Epoch [28/100] train_loss: 206.8765, val_loss: 260.0921, lr: 0.001000, 932.56s
2024-06-01 21:51:17,685 - INFO - epoch complete!
2024-06-01 21:51:17,686 - INFO - evaluating now!
2024-06-01 21:52:57,938 - INFO - Epoch [29/100] train_loss: 207.0389, val_loss: 254.0241, lr: 0.001000, 934.37s
2024-06-01 21:52:57,953 - INFO - Saved model at 29
2024-06-01 21:52:57,953 - INFO - Val loss decrease from 257.6097 to 254.0241, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch29.tar
2024-06-01 22:06:48,836 - INFO - epoch complete!
2024-06-01 22:06:48,837 - INFO - evaluating now!
2024-06-01 22:08:28,993 - INFO - Epoch [30/100] train_loss: 208.3327, val_loss: 259.6060, lr: 0.001000, 931.04s
2024-06-01 22:22:21,477 - INFO - epoch complete!
2024-06-01 22:22:21,477 - INFO - evaluating now!
2024-06-01 22:23:59,976 - INFO - Epoch [31/100] train_loss: 207.5500, val_loss: 252.7853, lr: 0.001000, 930.98s
2024-06-01 22:23:59,990 - INFO - Saved model at 31
2024-06-01 22:23:59,991 - INFO - Val loss decrease from 254.0241 to 252.7853, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch31.tar
2024-06-01 22:37:51,013 - INFO - epoch complete!
2024-06-01 22:37:51,014 - INFO - evaluating now!
2024-06-01 22:39:32,206 - INFO - Epoch [32/100] train_loss: 207.8641, val_loss: 258.9812, lr: 0.001000, 932.22s
2024-06-01 22:53:23,577 - INFO - epoch complete!
2024-06-01 22:53:23,578 - INFO - evaluating now!
2024-06-01 22:55:04,095 - INFO - Epoch [33/100] train_loss: 207.1805, val_loss: 276.1354, lr: 0.001000, 931.89s
2024-06-01 23:08:57,706 - INFO - epoch complete!
2024-06-01 23:08:57,707 - INFO - evaluating now!
2024-06-01 23:10:38,373 - INFO - Epoch [34/100] train_loss: 207.2622, val_loss: 253.6071, lr: 0.001000, 934.28s
2024-06-01 23:24:28,890 - INFO - epoch complete!
2024-06-01 23:24:28,891 - INFO - evaluating now!
2024-06-01 23:26:09,772 - INFO - Epoch [35/100] train_loss: 207.6151, val_loss: 262.2993, lr: 0.001000, 931.40s
2024-06-01 23:40:02,483 - INFO - epoch complete!
2024-06-01 23:40:02,483 - INFO - evaluating now!
2024-06-01 23:41:42,968 - INFO - Epoch [36/100] train_loss: 205.7791, val_loss: 273.8453, lr: 0.001000, 933.19s
2024-06-01 23:55:34,218 - INFO - epoch complete!
2024-06-01 23:55:34,218 - INFO - evaluating now!
2024-06-01 23:57:14,453 - INFO - Epoch [37/100] train_loss: 204.6374, val_loss: 261.7585, lr: 0.001000, 931.48s
2024-06-02 00:11:05,866 - INFO - epoch complete!
2024-06-02 00:11:05,866 - INFO - evaluating now!
2024-06-02 00:12:45,451 - INFO - Epoch [38/100] train_loss: 205.7321, val_loss: 263.5215, lr: 0.001000, 931.00s
2024-06-02 00:26:34,948 - INFO - epoch complete!
2024-06-02 00:26:34,948 - INFO - evaluating now!
2024-06-02 00:28:15,974 - INFO - Epoch [39/100] train_loss: 206.8990, val_loss: 258.2966, lr: 0.001000, 930.52s
2024-06-02 00:42:08,720 - INFO - epoch complete!
2024-06-02 00:42:08,720 - INFO - evaluating now!
2024-06-02 00:43:47,442 - INFO - Epoch [40/100] train_loss: 204.3076, val_loss: 260.8868, lr: 0.001000, 931.47s
2024-06-02 00:57:40,540 - INFO - epoch complete!
2024-06-02 00:57:40,541 - INFO - evaluating now!
2024-06-02 00:59:21,224 - INFO - Epoch [41/100] train_loss: 205.2017, val_loss: 254.3349, lr: 0.001000, 933.78s
2024-06-02 01:13:13,480 - INFO - epoch complete!
2024-06-02 01:13:13,481 - INFO - evaluating now!
2024-06-02 01:14:54,841 - INFO - Epoch [42/100] train_loss: 203.1805, val_loss: 264.4296, lr: 0.001000, 933.62s
2024-06-02 01:28:47,625 - INFO - epoch complete!
2024-06-02 01:28:47,626 - INFO - evaluating now!
2024-06-02 01:30:28,543 - INFO - Epoch [43/100] train_loss: 203.6396, val_loss: 259.1513, lr: 0.001000, 933.70s
2024-06-02 01:44:18,887 - INFO - epoch complete!
2024-06-02 01:44:18,887 - INFO - evaluating now!
2024-06-02 01:45:59,754 - INFO - Epoch [44/100] train_loss: 203.9493, val_loss: 259.3673, lr: 0.001000, 931.21s
2024-06-02 01:59:52,435 - INFO - epoch complete!
2024-06-02 01:59:52,435 - INFO - evaluating now!
2024-06-02 02:01:32,501 - INFO - Epoch [45/100] train_loss: 203.3525, val_loss: 248.7684, lr: 0.001000, 932.75s
2024-06-02 02:01:32,515 - INFO - Saved model at 45
2024-06-02 02:01:32,515 - INFO - Val loss decrease from 252.7853 to 248.7684, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch45.tar
2024-06-02 02:15:24,087 - INFO - epoch complete!
2024-06-02 02:15:24,088 - INFO - evaluating now!
2024-06-02 02:17:05,300 - INFO - Epoch [46/100] train_loss: 205.1190, val_loss: 265.5753, lr: 0.001000, 932.78s
2024-06-02 02:30:56,926 - INFO - epoch complete!
2024-06-02 02:30:56,926 - INFO - evaluating now!
2024-06-02 02:32:36,415 - INFO - Epoch [47/100] train_loss: 203.2473, val_loss: 246.0531, lr: 0.001000, 931.11s
2024-06-02 02:32:36,429 - INFO - Saved model at 47
2024-06-02 02:32:36,429 - INFO - Val loss decrease from 248.7684 to 246.0531, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch47.tar
2024-06-02 02:46:27,929 - INFO - epoch complete!
2024-06-02 02:46:27,929 - INFO - evaluating now!
2024-06-02 02:48:08,624 - INFO - Epoch [48/100] train_loss: 211.4406, val_loss: 248.9020, lr: 0.001000, 932.19s
2024-06-02 03:02:01,360 - INFO - epoch complete!
2024-06-02 03:02:01,361 - INFO - evaluating now!
2024-06-02 03:03:41,843 - INFO - Epoch [49/100] train_loss: 204.3310, val_loss: 264.3112, lr: 0.001000, 933.22s
2024-06-02 03:17:34,121 - INFO - epoch complete!
2024-06-02 03:17:34,121 - INFO - evaluating now!
2024-06-02 03:19:14,154 - INFO - Epoch [50/100] train_loss: 204.3157, val_loss: 260.9045, lr: 0.001000, 932.31s
2024-06-02 03:33:05,926 - INFO - epoch complete!
2024-06-02 03:33:05,927 - INFO - evaluating now!
2024-06-02 03:34:46,559 - INFO - Epoch [51/100] train_loss: 203.8496, val_loss: 264.6944, lr: 0.001000, 932.40s
2024-06-02 03:48:38,377 - INFO - epoch complete!
2024-06-02 03:48:38,377 - INFO - evaluating now!
2024-06-02 03:50:18,289 - INFO - Epoch [52/100] train_loss: 203.9600, val_loss: 253.1105, lr: 0.001000, 931.73s
2024-06-02 04:04:06,439 - INFO - epoch complete!
2024-06-02 04:04:06,440 - INFO - evaluating now!
2024-06-02 04:05:47,083 - INFO - Epoch [53/100] train_loss: 204.4481, val_loss: 246.7429, lr: 0.001000, 928.79s
2024-06-02 04:19:38,799 - INFO - epoch complete!
2024-06-02 04:19:38,800 - INFO - evaluating now!
2024-06-02 04:21:18,173 - INFO - Epoch [54/100] train_loss: 204.5558, val_loss: 266.3512, lr: 0.001000, 931.09s
2024-06-02 04:35:08,981 - INFO - epoch complete!
2024-06-02 04:35:08,982 - INFO - evaluating now!
2024-06-02 04:36:49,811 - INFO - Epoch [55/100] train_loss: 202.1143, val_loss: 261.3023, lr: 0.001000, 931.64s
2024-06-02 04:50:41,812 - INFO - epoch complete!
2024-06-02 04:50:41,813 - INFO - evaluating now!
2024-06-02 04:52:21,616 - INFO - Epoch [56/100] train_loss: 206.6905, val_loss: 263.0996, lr: 0.001000, 931.80s
2024-06-02 05:06:13,573 - INFO - epoch complete!
2024-06-02 05:06:13,574 - INFO - evaluating now!
2024-06-02 05:07:54,608 - INFO - Epoch [57/100] train_loss: 203.4453, val_loss: 259.2372, lr: 0.001000, 932.99s
2024-06-02 05:21:45,229 - INFO - epoch complete!
2024-06-02 05:21:45,229 - INFO - evaluating now!
2024-06-02 05:23:26,297 - INFO - Epoch [58/100] train_loss: 203.1945, val_loss: 255.1378, lr: 0.001000, 931.69s
2024-06-02 05:37:19,864 - INFO - epoch complete!
2024-06-02 05:37:19,865 - INFO - evaluating now!
2024-06-02 05:39:00,653 - INFO - Epoch [59/100] train_loss: 202.8245, val_loss: 252.3797, lr: 0.001000, 934.36s
2024-06-02 05:48:48,385 - INFO - epoch complete!
2024-06-02 05:48:48,385 - INFO - evaluating now!
2024-06-02 05:49:50,164 - INFO - Epoch [60/100] train_loss: 202.2165, val_loss: 265.2296, lr: 0.001000, 649.51s
2024-06-02 05:58:14,257 - INFO - epoch complete!
2024-06-02 05:58:14,257 - INFO - evaluating now!
2024-06-02 05:59:15,962 - INFO - Epoch [61/100] train_loss: 203.8056, val_loss: 247.0319, lr: 0.001000, 565.80s
2024-06-02 06:07:36,679 - INFO - epoch complete!
2024-06-02 06:07:36,680 - INFO - evaluating now!
2024-06-02 06:08:38,627 - INFO - Epoch [62/100] train_loss: 202.7236, val_loss: 250.9210, lr: 0.001000, 562.66s
2024-06-02 06:17:06,723 - INFO - epoch complete!
2024-06-02 06:17:06,724 - INFO - evaluating now!
2024-06-02 06:18:07,946 - INFO - Epoch [63/100] train_loss: 202.7450, val_loss: 252.0209, lr: 0.001000, 569.32s
2024-06-02 06:26:34,881 - INFO - epoch complete!
2024-06-02 06:26:34,882 - INFO - evaluating now!
2024-06-02 06:27:36,395 - INFO - Epoch [64/100] train_loss: 203.0284, val_loss: 253.6419, lr: 0.001000, 568.45s
2024-06-02 06:36:03,541 - INFO - epoch complete!
2024-06-02 06:36:03,541 - INFO - evaluating now!
2024-06-02 06:37:05,716 - INFO - Epoch [65/100] train_loss: 203.2966, val_loss: 258.6208, lr: 0.001000, 569.32s
2024-06-02 06:45:32,021 - INFO - epoch complete!
2024-06-02 06:45:32,021 - INFO - evaluating now!
2024-06-02 06:46:33,408 - INFO - Epoch [66/100] train_loss: 201.1472, val_loss: 254.5494, lr: 0.001000, 567.69s
2024-06-02 06:52:53,076 - INFO - epoch complete!
2024-06-02 06:52:53,077 - INFO - evaluating now!
2024-06-02 06:53:14,182 - INFO - Epoch [67/100] train_loss: 202.9095, val_loss: 248.4724, lr: 0.001000, 400.77s
2024-06-02 06:56:12,209 - INFO - epoch complete!
2024-06-02 06:56:12,209 - INFO - evaluating now!
2024-06-02 06:56:33,787 - INFO - Epoch [68/100] train_loss: 203.5269, val_loss: 243.7558, lr: 0.001000, 199.60s
2024-06-02 06:56:33,800 - INFO - Saved model at 68
2024-06-02 06:56:33,800 - INFO - Val loss decrease from 246.0531 to 243.7558, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch68.tar
2024-06-02 06:59:31,620 - INFO - epoch complete!
2024-06-02 06:59:31,620 - INFO - evaluating now!
2024-06-02 06:59:53,054 - INFO - Epoch [69/100] train_loss: 203.8569, val_loss: 243.0760, lr: 0.001000, 199.25s
2024-06-02 06:59:53,067 - INFO - Saved model at 69
2024-06-02 06:59:53,067 - INFO - Val loss decrease from 243.7558 to 243.0760, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch69.tar
2024-06-02 07:02:51,108 - INFO - epoch complete!
2024-06-02 07:02:51,109 - INFO - evaluating now!
2024-06-02 07:03:12,570 - INFO - Epoch [70/100] train_loss: 201.7721, val_loss: 248.3114, lr: 0.001000, 199.50s
2024-06-02 07:06:10,571 - INFO - epoch complete!
2024-06-02 07:06:10,572 - INFO - evaluating now!
2024-06-02 07:06:32,184 - INFO - Epoch [71/100] train_loss: 200.8977, val_loss: 247.1181, lr: 0.001000, 199.61s
2024-06-02 07:09:31,638 - INFO - epoch complete!
2024-06-02 07:09:31,638 - INFO - evaluating now!
2024-06-02 07:09:53,147 - INFO - Epoch [72/100] train_loss: 203.0513, val_loss: 268.1476, lr: 0.001000, 200.96s
2024-06-02 07:12:52,399 - INFO - epoch complete!
2024-06-02 07:12:52,399 - INFO - evaluating now!
2024-06-02 07:13:14,161 - INFO - Epoch [73/100] train_loss: 202.6146, val_loss: 259.6630, lr: 0.001000, 201.01s
2024-06-02 07:16:12,546 - INFO - epoch complete!
2024-06-02 07:16:12,547 - INFO - evaluating now!
2024-06-02 07:16:34,033 - INFO - Epoch [74/100] train_loss: 201.6456, val_loss: 268.1348, lr: 0.001000, 199.87s
2024-06-02 07:19:32,667 - INFO - epoch complete!
2024-06-02 07:19:32,667 - INFO - evaluating now!
2024-06-02 07:19:54,241 - INFO - Epoch [75/100] train_loss: 201.5858, val_loss: 248.2806, lr: 0.001000, 200.21s
2024-06-02 07:22:53,228 - INFO - epoch complete!
2024-06-02 07:22:53,229 - INFO - evaluating now!
2024-06-02 07:23:14,866 - INFO - Epoch [76/100] train_loss: 201.2184, val_loss: 242.3918, lr: 0.001000, 200.62s
2024-06-02 07:23:14,878 - INFO - Saved model at 76
2024-06-02 07:23:14,879 - INFO - Val loss decrease from 243.0760 to 242.3918, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch76.tar
2024-06-02 07:26:13,364 - INFO - epoch complete!
2024-06-02 07:26:13,365 - INFO - evaluating now!
2024-06-02 07:26:34,931 - INFO - Epoch [77/100] train_loss: 201.7833, val_loss: 259.5029, lr: 0.001000, 200.05s
2024-06-02 07:29:34,353 - INFO - epoch complete!
2024-06-02 07:29:34,354 - INFO - evaluating now!
2024-06-02 07:29:55,844 - INFO - Epoch [78/100] train_loss: 200.4980, val_loss: 246.4881, lr: 0.001000, 200.91s
2024-06-02 07:32:55,971 - INFO - epoch complete!
2024-06-02 07:32:55,971 - INFO - evaluating now!
2024-06-02 07:33:17,485 - INFO - Epoch [79/100] train_loss: 204.0189, val_loss: 249.1439, lr: 0.001000, 201.64s
2024-06-02 07:36:17,637 - INFO - epoch complete!
2024-06-02 07:36:17,638 - INFO - evaluating now!
2024-06-02 07:36:38,998 - INFO - Epoch [80/100] train_loss: 202.4613, val_loss: 252.7538, lr: 0.001000, 201.51s
2024-06-02 07:39:38,580 - INFO - epoch complete!
2024-06-02 07:39:38,580 - INFO - evaluating now!
2024-06-02 07:40:00,190 - INFO - Epoch [81/100] train_loss: 200.3942, val_loss: 246.6706, lr: 0.001000, 201.19s
2024-06-02 07:42:59,343 - INFO - epoch complete!
2024-06-02 07:42:59,344 - INFO - evaluating now!
2024-06-02 07:43:20,876 - INFO - Epoch [82/100] train_loss: 200.7606, val_loss: 253.9752, lr: 0.001000, 200.69s
2024-06-02 07:46:19,468 - INFO - epoch complete!
2024-06-02 07:46:19,469 - INFO - evaluating now!
2024-06-02 07:46:41,083 - INFO - Epoch [83/100] train_loss: 200.3903, val_loss: 252.1708, lr: 0.001000, 200.21s
2024-06-02 07:49:39,748 - INFO - epoch complete!
2024-06-02 07:49:39,748 - INFO - evaluating now!
2024-06-02 07:50:01,043 - INFO - Epoch [84/100] train_loss: 200.9891, val_loss: 250.3116, lr: 0.001000, 199.96s
2024-06-02 07:52:59,860 - INFO - epoch complete!
2024-06-02 07:52:59,861 - INFO - evaluating now!
2024-06-02 07:53:21,346 - INFO - Epoch [85/100] train_loss: 200.4497, val_loss: 248.7921, lr: 0.001000, 200.30s
2024-06-02 07:56:20,364 - INFO - epoch complete!
2024-06-02 07:56:20,365 - INFO - evaluating now!
2024-06-02 07:56:41,967 - INFO - Epoch [86/100] train_loss: 201.2912, val_loss: 251.1631, lr: 0.001000, 200.62s
2024-06-02 07:59:41,530 - INFO - epoch complete!
2024-06-02 07:59:41,531 - INFO - evaluating now!
2024-06-02 08:00:03,476 - INFO - Epoch [87/100] train_loss: 202.2317, val_loss: 252.0613, lr: 0.001000, 201.51s
2024-06-02 08:03:02,997 - INFO - epoch complete!
2024-06-02 08:03:02,997 - INFO - evaluating now!
2024-06-02 08:03:24,570 - INFO - Epoch [88/100] train_loss: 201.1328, val_loss: 260.6225, lr: 0.001000, 201.09s
2024-06-02 08:06:23,416 - INFO - epoch complete!
2024-06-02 08:06:23,417 - INFO - evaluating now!
2024-06-02 08:06:45,141 - INFO - Epoch [89/100] train_loss: 200.4026, val_loss: 252.1495, lr: 0.001000, 200.57s
2024-06-02 08:09:44,548 - INFO - epoch complete!
2024-06-02 08:09:44,549 - INFO - evaluating now!
2024-06-02 08:10:06,153 - INFO - Epoch [90/100] train_loss: 201.1926, val_loss: 259.6774, lr: 0.001000, 201.01s
2024-06-02 08:13:05,236 - INFO - epoch complete!
2024-06-02 08:13:05,236 - INFO - evaluating now!
2024-06-02 08:13:26,832 - INFO - Epoch [91/100] train_loss: 200.5146, val_loss: 272.1934, lr: 0.001000, 200.68s
2024-06-02 08:16:25,532 - INFO - epoch complete!
2024-06-02 08:16:25,532 - INFO - evaluating now!
2024-06-02 08:16:47,394 - INFO - Epoch [92/100] train_loss: 199.9212, val_loss: 258.9139, lr: 0.001000, 200.56s
2024-06-02 08:19:47,132 - INFO - epoch complete!
2024-06-02 08:19:47,132 - INFO - evaluating now!
2024-06-02 08:20:08,838 - INFO - Epoch [93/100] train_loss: 201.3145, val_loss: 271.9407, lr: 0.001000, 201.44s
2024-06-02 08:23:07,406 - INFO - epoch complete!
2024-06-02 08:23:07,407 - INFO - evaluating now!
2024-06-02 08:23:28,998 - INFO - Epoch [94/100] train_loss: 201.1078, val_loss: 240.3706, lr: 0.001000, 200.16s
2024-06-02 08:23:29,011 - INFO - Saved model at 94
2024-06-02 08:23:29,011 - INFO - Val loss decrease from 242.3918 to 240.3706, saving to ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD_epoch94.tar
2024-06-02 08:26:27,574 - INFO - epoch complete!
2024-06-02 08:26:27,575 - INFO - evaluating now!
2024-06-02 08:26:49,024 - INFO - Epoch [95/100] train_loss: 200.7081, val_loss: 249.0194, lr: 0.001000, 200.01s
2024-06-02 08:29:47,901 - INFO - epoch complete!
2024-06-02 08:29:47,901 - INFO - evaluating now!
2024-06-02 08:30:09,386 - INFO - Epoch [96/100] train_loss: 200.3749, val_loss: 247.7026, lr: 0.001000, 200.36s
2024-06-02 08:33:08,444 - INFO - epoch complete!
2024-06-02 08:33:08,445 - INFO - evaluating now!
2024-06-02 08:33:29,911 - INFO - Epoch [97/100] train_loss: 200.8381, val_loss: 242.8033, lr: 0.001000, 200.52s
2024-06-02 08:36:28,653 - INFO - epoch complete!
2024-06-02 08:36:28,653 - INFO - evaluating now!
2024-06-02 08:36:50,535 - INFO - Epoch [98/100] train_loss: 200.8410, val_loss: 245.3464, lr: 0.001000, 200.62s
2024-06-02 08:39:49,252 - INFO - epoch complete!
2024-06-02 08:39:49,252 - INFO - evaluating now!
2024-06-02 08:40:10,710 - INFO - Epoch [99/100] train_loss: 200.2675, val_loss: 256.8578, lr: 0.001000, 200.17s
2024-06-02 08:40:10,711 - INFO - Trained totally 100 epochs, average train time is 576.543s, average eval time is 69.337s
2024-06-02 08:40:10,722 - INFO - Loaded model at 94
2024-06-02 08:40:10,722 - INFO - Saved model at ./libcity/cache/67792/model_cache/GEML_NYCTAXI_OD.m
2024-06-02 08:40:10,734 - INFO - Start evaluating ...
2024-06-02 08:40:41,984 - INFO - Note that you select the single mode to evaluate!
2024-06-02 08:40:41,987 - INFO - Evaluate result is saved at ./libcity/cache/67792/evaluate_cache/2024_06_02_08_40_41_GEML_NYCTAXI_OD.csv
2024-06-02 08:40:41,996 - INFO - 
       MAE  MAPE       MSE  ...  masked_RMSE        R2      EVAR
1  0.05523   inf  0.222184  ...     3.263436  0.255345  0.256226

[1 rows x 10 columns]
